{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import IPython.display as display\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuraciones de TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos esta variable para no usar la GPU si llega a estar ocupada\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobar que estoy ejecutandome en modo eagerly\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log device placement corresponde a si yo quiero ver la informacion en donde se mapea o guardan las variables que creo\n",
    "config = tf.ConfigProto(log_device_placement=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como construir tu propio dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../DataSets/UCF101 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../DataSets/UCF101')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = pathlib.Path(\"../DataSets/UCF101\")\n",
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../DataSets/UCF101/flow\n",
      "../DataSets/UCF101/frames\n"
     ]
    }
   ],
   "source": [
    "for folder in root_path.iterdir():\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13320"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_rgb_path = list(root_path.glob('frames/*'))\n",
    "videos_rgb_path = [str(video) for video in videos_rgb_path]\n",
    "len(videos_rgb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../DataSets/UCF101/frames/v_PlayingPiano_g24_c04',\n",
       " '../DataSets/UCF101/frames/v_RopeClimbing_g20_c02',\n",
       " '../DataSets/UCF101/frames/v_BlowingCandles_g18_c01',\n",
       " '../DataSets/UCF101/frames/v_Rowing_g05_c04',\n",
       " '../DataSets/UCF101/frames/v_Archery_g23_c07',\n",
       " '../DataSets/UCF101/frames/v_HeadMassage_g16_c04',\n",
       " '../DataSets/UCF101/frames/v_JumpingJack_g07_c04',\n",
       " '../DataSets/UCF101/frames/v_Shotput_g08_c07',\n",
       " '../DataSets/UCF101/frames/v_Skiing_g16_c04',\n",
       " '../DataSets/UCF101/frames/v_PlayingCello_g09_c05']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_rgb_path[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../DataSets/UCF101/frames/v_PushUps_g10_c03\n"
     ]
    }
   ],
   "source": [
    "video_path = pathlib.Path(random.choice(videos_rgb_path))\n",
    "frames_path = list(video_path.glob('*'))\n",
    "frames_path = [str(frame_path) for frame_path in frames_path]\n",
    "print(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.display(display.Image(random.choice(frames_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ApplyEyeMakeup',\n",
       " 'ApplyLipstick',\n",
       " 'Archery',\n",
       " 'BabyCrawling',\n",
       " 'BalanceBeam',\n",
       " 'BandMarching',\n",
       " 'BaseballPitch',\n",
       " 'BasketballDunk',\n",
       " 'Basketball',\n",
       " 'BenchPress']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres_clases = sorted(item.name for item in videos_rgb_path if item.is_dir())\n",
    "nombres_clases = [clase.split(\"_\")[1] for clase in nombres_clases]\n",
    "\n",
    "#Extraccion de todos los tipos de clases en un vector de python\n",
    "clases = []\n",
    "for clase in nombres_clases:\n",
    "    if clase not in clases:\n",
    "        clases.append(clase)\n",
    "\n",
    "#label_names, __ = tf.unique(label_names)\n",
    "nombres_clases = clases\n",
    "nombres_clases[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clase_a_numero = dict((name, index) for index,name in enumerate(nombres_clases))\n",
    "len(clase_a_numero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63, 74, 13, 75, 2, 38, 47, 78, 80, 58]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clases_videos = [clase_a_numero[item.name.split(\"_\")[1]] for item in videos_rgb_path]\n",
    "clases_videos[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como cargar los videos usando la libreria de tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionar_cuadro_aleatorio(imagen, nueva_dimension):\n",
    "    pos_y = randint(0,imagen.shape[0].value - nueva_dimension)\n",
    "    pos_x = randint(0,imagen.shape[1].value - nueva_dimension)\n",
    "    return imagen[pos_y : pos_y + nueva_dimension , pos_x : pos_x + nueva_dimension, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionar_extension_temporal(video, nro_frames):\n",
    "    extension = randint(0,video.shape[0].value - nro_frames)\n",
    "    return video[extension : extension + nro_frames, : , :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion sin ser usada aun\n",
    "def procesar_frame(frame_path):\n",
    "    frame_raw = tf.io.read_file(str(frame_path))\n",
    "    frame_tensor = tf.image.decode_image(frame_raw, channels=3)\n",
    "    frame_tensor = tf.image.resize(frame_tensor,[128,171])\n",
    "    return frame_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_preprocesar_video(video_path):\n",
    "    video = []\n",
    "    for frame_path in sorted(list(pathlib.Path(video_path).glob('*'))):\n",
    "        frame_raw = tf.io.read_file(str(frame_path))\n",
    "        frame_tensor = tf.image.decode_image(frame_raw, channels=3)\n",
    "        frame_tensor = tf.image.resize(frame_tensor,[128,171])\n",
    "        frame_tensor = seleccionar_cuadro_aleatorio(frame_tensor, 112)\n",
    "        video.append(frame_tensor)\n",
    "    video = tf.convert_to_tensor(video)\n",
    "    video = seleccionar_extension_temporal(video, 16)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forma de cargar los videos para usarlos como dataset pero ocupa mucha memoria, entonces se va hacer buffering con tensor\n",
    "videos = []\n",
    "for video_path in videos_rgb_path:\n",
    "    video = []\n",
    "    for frame_path in sorted(list(video_path.glob('*'))):\n",
    "        frame_raw = tf.io.read_file(str(frame_path))\n",
    "        frame_tensor = tf.image.decode_image(frame_raw, channels=3)\n",
    "        frame_tensor = tf.image.resize(frame_tensor,[128,171])\n",
    "        frame_tensor = seleccionar_cuadro_aleatorio(frame_tensor, 112)\n",
    "        video.append(frame_tensor)\n",
    "    video = tf.convert_to_tensor(video)\n",
    "    video = seleccionar_extension_temporal(video, 16)\n",
    "    videos.append(video)\n",
    "videos = tf.convert_to_tensor(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = []\n",
    "for frame_path in sorted(list(video_path.glob('*'))):\n",
    "    frame_raw = tf.io.read_file(str(frame_path))\n",
    "    frame_tensor = tf.image.decode_image(frame_raw, channels=3)\n",
    "    frame_tensor = tf.image.resize(frame_tensor,[128,171])\n",
    "    video.append(frame_tensor)\n",
    "video = tf.convert_to_tensor(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construccion del dataset a partir de los path y cargar los datos usando prefetch\n",
    "videos_rgb_path_ds = tf.data.Dataset.from_tensor_slices(videos_rgb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_rgb_path_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument should be a path or str object, not <class 'tensorflow.python.framework.ops.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ffe0223ecf83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvideos_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideos_rgb_path_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcargar_preprocesar_video\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1582\u001b[0m       return DatasetV1Adapter(\n\u001b[1;32m   1583\u001b[0m           ParallelMapDataset(\n\u001b[0;32m-> 1584\u001b[0;31m               self, map_func, num_parallel_calls, preserve_cardinality=False))\n\u001b[0m\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality)\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.map()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2770\u001b[0m     super(ParallelMapDataset, self).__init__(\n\u001b[0;32m-> 2771\u001b[0;31m         input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality)\n\u001b[0m\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality)\u001b[0m\n\u001b[1;32m   2735\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m     self._map_func = StructuredFunctionWrapper(\n\u001b[0;32m-> 2737\u001b[0;31m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[1;32m   2738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2739\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_variant_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, defun_kwargs)\u001b[0m\n\u001b[1;32m   2122\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_data_structured_function_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2124\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m       \u001b[0;31m# Use the private method that will execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m    488\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;34m\"\"\"Adds this function into the graph g.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;31m# Adds this function into 'g'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;34m\"\"\"Creates the function definition if it's not created yet.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_by_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_caller_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         whitelisted_stateful_ops=self._whitelisted_stateful_ops)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extra_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(func, arg_names, arg_types, name, capture_by_value, device, colocation_stack, container, collections_ref, arg_shapes, whitelisted_stateful_ops)\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;31m# Call func and gather the output tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;31m# There is no way of distinguishing between a function not returning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mtf_data_structured_function_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2097\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-b8c18eea05a7>\u001b[0m in \u001b[0;36mcargar_preprocesar_video\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcargar_preprocesar_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mframe_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mframe_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mframe_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/pathlib.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindowsPath\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mPosixPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m             raise NotImplementedError(\"cannot instantiate %r on your system\"\n",
      "\u001b[0;32m/usr/lib/python3.5/pathlib.py\u001b[0m in \u001b[0;36m_from_parts\u001b[0;34m(cls, args, init)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;31m# right flavour.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/pathlib.py\u001b[0m in \u001b[0;36m_parse_args\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 raise TypeError(\n\u001b[1;32m    642\u001b[0m                     \u001b[0;34m\"argument should be a path or str object, not %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                     % type(a))\n\u001b[0m\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument should be a path or str object, not <class 'tensorflow.python.framework.ops.Tensor'>"
     ]
    }
   ],
   "source": [
    "videos_ds = videos_rgb_path_ds.map(cargar_preprocesar_video, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in videos_rgb_path_ds.take(1):\n",
    "    tf.print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
