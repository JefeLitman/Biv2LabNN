{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0919 19:48:55.856263 139767441942272 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import IPython.display as display\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuraciones de TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos esta variable para no usar la GPU si llega a estar ocupada\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobar que estoy ejecutandome en modo eagerly\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log device placement corresponde a si yo quiero ver la informacion en donde se mapea o guardan las variables que creo\n",
    "config = tf.ConfigProto(log_device_placement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como construir tu propio dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../DataSets/UCF101 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../DataSets/UCF101')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = pathlib.Path(\"../DataSets/UCF101\")\n",
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../DataSets/UCF101/flow\n",
      "../DataSets/UCF101/frames\n"
     ]
    }
   ],
   "source": [
    "for folder in root_path.iterdir():\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13320"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_rgb_path = list(root_path.glob('frames/*'))\n",
    "videos_rgb_path = [str(video) for video in videos_rgb_path]\n",
    "len(videos_rgb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../DataSets/UCF101/frames/v_PlayingPiano_g24_c04',\n",
       " '../DataSets/UCF101/frames/v_RopeClimbing_g20_c02',\n",
       " '../DataSets/UCF101/frames/v_BlowingCandles_g18_c01',\n",
       " '../DataSets/UCF101/frames/v_Rowing_g05_c04',\n",
       " '../DataSets/UCF101/frames/v_Archery_g23_c07',\n",
       " '../DataSets/UCF101/frames/v_HeadMassage_g16_c04',\n",
       " '../DataSets/UCF101/frames/v_JumpingJack_g07_c04',\n",
       " '../DataSets/UCF101/frames/v_Shotput_g08_c07',\n",
       " '../DataSets/UCF101/frames/v_Skiing_g16_c04',\n",
       " '../DataSets/UCF101/frames/v_PlayingCello_g09_c05']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_rgb_path[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../DataSets/UCF101/frames/v_PlayingCello_g09_c04\n"
     ]
    }
   ],
   "source": [
    "video_path = pathlib.Path(random.choice(videos_rgb_path))\n",
    "frames_path = list(video_path.glob('*'))\n",
    "frames_path = [str(frame_path) for frame_path in frames_path]\n",
    "print(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.display(display.Image(random.choice(frames_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ApplyEyeMakeup',\n",
       " 'ApplyLipstick',\n",
       " 'Archery',\n",
       " 'BabyCrawling',\n",
       " 'BalanceBeam',\n",
       " 'BandMarching',\n",
       " 'BaseballPitch',\n",
       " 'BasketballDunk',\n",
       " 'Basketball',\n",
       " 'BenchPress']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres_clases = sorted(pathlib.Path(item).name for item in videos_rgb_path if pathlib.Path(item).is_dir())\n",
    "nombres_clases = [clase.split(\"_\")[1] for clase in nombres_clases]\n",
    "\n",
    "#Extraccion de todos los tipos de clases en un vector de python\n",
    "clases = []\n",
    "for clase in nombres_clases:\n",
    "    if clase not in clases:\n",
    "        clases.append(clase)\n",
    "\n",
    "#label_names, __ = tf.unique(label_names)\n",
    "nombres_clases = clases\n",
    "nombres_clases[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clase_a_numero = dict((name, index) for index,name in enumerate(nombres_clases))\n",
    "len(clase_a_numero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63, 74, 13, 75, 2, 38, 47, 78, 80, 58]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clases_videos = [clase_a_numero[pathlib.Path(item).name.split(\"_\")[1]] for item in videos_rgb_path]\n",
    "clases_videos[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como cargar los videos usando la libreria de tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forma de cargar los videos para usarlos como dataset pero ocupa mucha memoria, entonces se va hacer buffering con tensor\n",
    "videos = []\n",
    "for video_path in videos_rgb_path:\n",
    "    video = []\n",
    "    for frame_path in sorted(list(video_path.glob('*'))):\n",
    "        frame_raw = tf.io.read_file(str(frame_path))\n",
    "        frame_tensor = tf.image.decode_image(frame_raw, channels=3)\n",
    "        frame_tensor = tf.image.resize(frame_tensor,[128,171])\n",
    "        frame_tensor = seleccionar_cuadro_aleatorio(frame_tensor, 112)\n",
    "        video.append(frame_tensor)\n",
    "    video = tf.convert_to_tensor(video)\n",
    "    video = seleccionar_extension_temporal(video, 16)\n",
    "    videos.append(video)\n",
    "videos = tf.convert_to_tensor(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionar_cuadro_aleatorio(imagen, nueva_dimension):\n",
    "    pos_y = randint(0,imagen.shape[0].value - nueva_dimension)\n",
    "    pos_x = randint(0,imagen.shape[1].value - nueva_dimension)\n",
    "    return imagen[pos_y : pos_y + nueva_dimension , pos_x : pos_x + nueva_dimension, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionar_extension_temporal(video, nro_frames):\n",
    "    extension = randint(0,video.shape[0].value - nro_frames)\n",
    "    return video[extension : extension + nro_frames, : , :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion sin ser usada aun\n",
    "def procesar_frame(frame_path):\n",
    "    frame_raw = tf.io.read_file(str(frame_path))\n",
    "    frame_tensor = tf.image.decode_image(frame_raw, channels=3)\n",
    "    frame_tensor = tf.image.resize(frame_tensor,[128,171])\n",
    "    return frame_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_preprocesar_video(video_path):\n",
    "    video = []\n",
    "    for frame_path in sorted(list(pathlib.Path(video_path.eval(session=sesion)).glob('*'))):\n",
    "        frame_raw = tf.io.read_file(str(frame_path))\n",
    "        frame_tensor = tf.image.decode_image(frame_raw, channels=3)\n",
    "        frame_tensor = tf.image.resize(frame_tensor,[128,171])\n",
    "        frame_tensor = seleccionar_cuadro_aleatorio(frame_tensor, 112)\n",
    "        video.append(frame_tensor)\n",
    "    video = tf.convert_to_tensor(video)\n",
    "    video = seleccionar_extension_temporal(video, 16)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creacion de los datasets de TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Construccion del dataset a partir de los path y cargar los datos usando prefetch\n",
    "videos_rgb_path_ds = tf.data.Dataset.from_tensor_slices(videos_rgb_path)\n",
    "videos_rgb_path_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f1df95d09e8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sesion = tf.Session(config=config)\n",
    "sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c0a4e392cf1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melemento\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideos_rgb_path_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mvideos_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideos_rgb_path_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcargar_preprocesar_video\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1774\u001b[0m       return DatasetV1Adapter(\n\u001b[1;32m   1775\u001b[0m           ParallelMapDataset(\n\u001b[0;32m-> 1776\u001b[0;31m               self, map_func, num_parallel_calls, preserve_cardinality=False))\n\u001b[0m\u001b[1;32m   1777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Use `tf.data.Dataset.map()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3226\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3228\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3229\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3230\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   2553\u001b[0m       \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2554\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2555\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 1355\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1543\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1546\u001b[0m         self._function_attributes)\n\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                           converted_func)\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2547\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   2548\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2549\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-3f929a05d619>\u001b[0m in \u001b[0;36mcargar_preprocesar_video\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcargar_preprocesar_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mframe_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msesion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mframe_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mframe_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \"\"\"\n\u001b[0;32m--> 731\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5574\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5575\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5576\u001b[0;31m       raise ValueError(\"Cannot use the given session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5577\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5578\u001b[0m                        \"graph.\")\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph."
     ]
    }
   ],
   "source": [
    "for elemento in videos_rgb_path_ds:\n",
    "    videos_ds = videos_rgb_path_ds.map(cargar_preprocesar_video, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "for elemento in videos_rgb_path_ds:\n",
    "    print(elemento.graph == sesion.graph)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f1df95d09e8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_ds = videos_rgb_path_ds.map(cargar_preprocesar_video, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas_ds = tf.data.Dataset.from_tensor_slices(clases_videos)\n",
    "etiquetas_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LTC import LTC\n",
    "\n",
    "\n",
    "\n",
    "model = LTC(\n",
    "    entrada = None,\n",
    "    etiquetas = None,\n",
    "    num_clases = None,\n",
    "    batch_size = 30,\n",
    "    dropout = 0.5,\n",
    "    entramiento = True):\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors={'step': model.global_step,\n",
    "               'loss': model.cost,\n",
    "               'precision': precision},\n",
    "      every_n_iter=100)\n",
    "\n",
    "training_session = tf.train.MonitoredTrainingSession(\n",
    "    checkpoint_dir=\"./Checkpoints\",\n",
    "      hooks=[logging_hook, _LearningRateSetterHook()],\n",
    "      chief_only_hooks=[summary_hook],\n",
    "      # Since we provide a SummarySaverHook, we need to disable default\n",
    "      # SummarySaverHook. To do that we set save_summaries_steps to 0.\n",
    "      save_summaries_steps=0,\n",
    "      config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.math.purdue.edu/~nwinovic/slides/Getting_Started_with_TensorFlow_II.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
