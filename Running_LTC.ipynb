{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuracion de grafica a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# lA ID de la GPU a usar, puede ser desde 0 hasta las N GPU's. Si es -1 significa que es en la CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import interact, IntSlider\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from Models.ltc_models import *\n",
    "!wget -q https://raw.githubusercontent.com/JefeLitman/VideoDataGenerator/master/DatasetsLoaderUtils.py -O DatasetsLoaderUtils.py\n",
    "from DatasetsLoaderUtils import load_videoFrames_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow_core.python.keras.api._v2.keras.activations' from '/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/api/_v2/keras/activations/__init__.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuraciones para Tensorflow y Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(8128)\n",
    "np.random.seed(8128)\n",
    "tf.random.set_seed(8128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jefelitman/DataSets/ucf101/split_1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = \"/home/jefelitman/DataSets/ucf101/split_1\"\n",
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "batch_size = 30\n",
    "size = [112, 112]\n",
    "frames = 16\n",
    "canales = 3\n",
    "video_shape = tuple([frames]+size[::-1]+[canales])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def time_sampling(video):\n",
    "    if len(video) < 60:\n",
    "        new_video = np.concatenate([video, np.zeros([60 - len(video), 58, 58, 3])], axis=0)\n",
    "    else:\n",
    "        new_video = video\n",
    "    mitad = len(new_video)//2\n",
    "    return new_video[mitad-30:mitad+30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_videoFrames_from_path(root_path, lambda x: x, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = dataset.data_generator(1, canales)\n",
    "test_gen = dataset.data_generator(2, canales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen_sampling():\n",
    "    for v, l in train_gen:\n",
    "        paso = len(v)//16\n",
    "        if paso == 0:\n",
    "            video = np.concatenate([v, np.zeros([16 - len(v), 112, 112, 3])], axis=0)\n",
    "        else:\n",
    "            video = v\n",
    "        for j in range(paso):\n",
    "            yield video[j::paso][:16], l\n",
    "def test_gen_sampling():\n",
    "    for v, l in test_gen:\n",
    "        paso = len(v)//16\n",
    "        if paso == 0:\n",
    "            video = np.concatenate([v, np.zeros([16 - len(v), 112, 112, 3])], axis=0)\n",
    "        else:\n",
    "            video = v\n",
    "        for j in range(paso):\n",
    "            yield video[j::paso][:16], l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3567.9666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "107039/30 # Cantidad de batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(video, label):\n",
    "    return video/255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_flip_horizontal(video, label):\n",
    "    return tf.reverse(video, [2]), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "train_data = tf.data.Dataset.from_generator(train_gen_sampling, (tf.float32, tf.int64), \n",
    "                                            (video_shape, []))\n",
    "train_data = train_data.cache('/home/jefelitman/DataSets/temporal_cache_data/train').map(scale, 24)\n",
    "#train_data = train_data.concatenate(train_data.map(video_flip_horizontal, 24))\n",
    "\n",
    "#  Test dataset\n",
    "test_data = tf.data.Dataset.from_generator(test_gen_sampling, (tf.float32, tf.int64), \n",
    "                                            (video_shape, []))\n",
    "test_data = test_data.cache(\"/home/jefelitman/DataSets/temporal_cache_data/test\").map(scale, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal LTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construccion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jefelitman/Saved_Models/trained_ucf/No_Encoder/no_inception/LTC-ori_split1_112x112x16_SGD_RGB_lr=0.001_DO_IC_TDM_S255_E20'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrada de la red neuronal\n",
    "dropout = 0.5\n",
    "lr = 1e-3\n",
    "weigh_decay = 5e-3\n",
    "\n",
    "ltc_save_path = '/home/jefelitman/Saved_Models/trained_ucf/No_Encoder/no_inception/LTC-ori_split1_{w}x{h}x{f}_SGD_'.format(\n",
    "        w=size[0], h=size[1],f=frames)\n",
    "if canales == 3:\n",
    "    ltc_save_path += 'RGB_'\n",
    "else:\n",
    "    ltc_save_path += 'B&N_'\n",
    "\n",
    "ltc_save_path += 'lr={l}_DO_IC_TDM_S255_E{e}'.format(l = lr, e = epoch)\n",
    "\n",
    "#Creacion de la carpeta donde se salvara el modelo\n",
    "if not os.path.isdir(ltc_save_path):\n",
    "    os.mkdir(ltc_save_path)\n",
    "model_saves_path = os.path.join(ltc_save_path,'model_saves')\n",
    "if not os.path.isdir(model_saves_path):\n",
    "    os.mkdir(model_saves_path)\n",
    "ltc_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametros para la compilacion del modelo\n",
    "optimizador = keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "#optimizador = keras.optimizers.Adam(learning_rate=lr)\n",
    "perdida = keras.losses.SparseCategoricalCrossentropy(name=\"loss\")\n",
    "precision = keras.metrics.SparseCategoricalAccuracy(name=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltc = get_LTC_original(video_shape, len(dataset.to_class), dropout, weigh_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilacion del modelo\n",
    "ltc.compile(optimizer = optimizador,\n",
    "           loss = perdida,\n",
    "           metrics = [precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(ltc, 'LTC.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ltc = keras.models.load_model(os.path.join(ltc_save_path,'ltc_final_1000.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LTC_original\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_video (InputLayer)     [(None, 16, 112, 112, 3)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 16, 112, 112, 64)  5248      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 16, 56, 56, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 16, 56, 56, 128)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 8, 28, 28, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 8, 28, 28, 256)    884992    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 4, 14, 14, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 4, 14, 14, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 2, 7, 7, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 2, 7, 7, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 1, 3, 3, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2048)              4720640   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 101)               206949    \n",
      "=================================================================\n",
      "Total params: 13,774,949\n",
      "Trainable params: 13,774,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ltc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargo los pesos pre entrenados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pesos del C3D"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c3d_weights = h5py.File('/home/jefelitman/Saved_Models/c3d-sports1M_weights.h5', 'r')\n",
    "print(c3d_weights.keys())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c3d_weights['layer_0'].keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "weights = []\n",
    "for capa in ['layer_0','layer_2','layer_4','layer_5','layer_5']:\n",
    "    weights.append([\n",
    "        np.moveaxis(np.r_[c3d_weights[capa]['param_0']], (0,1),(4,3)), #Cambio los ejes porque c3d estan con canales primero\n",
    "        np.r_[c3d_weights[capa]['param_1']]\n",
    "                   ])\n",
    "for index, capa in enumerate(['conv3d_1','conv3d_2','conv3d_3','conv3d_4','conv3d_5']):\n",
    "    ltc.get_layer(capa).set_weights(weights[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pesos de la InceptionV3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inceptionv3 = keras.applications.InceptionV3(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for layer, index in [('conv3d_1',1),('conv3d_2',4),('conv3d_3',7),('conv3d_4',11),('conv3d_5',14)]:\n",
    "    old_weights, old_bias = ltc.get_layer(layer).get_weights()\n",
    "    new_weight = np.zeros(old_weights.shape)\n",
    "    new_bias = np.zeros(old_bias.shape)\n",
    "    pesos = inceptionv3.layers[index].get_weights()[0]\n",
    "    for entrada in range(old_weights.shape[3]):\n",
    "        for salida in range(old_weights.shape[4]):\n",
    "            new_weight[:,:,:,entrada,salida] = np.stack([pesos[:,:,entrada%pesos.shape[2],salida%pesos.shape[3]], \n",
    "                                                         pesos[:,:,entrada%pesos.shape[2],salida%pesos.shape[3]], \n",
    "                                                         pesos[:,:,entrada%pesos.shape[2],salida%pesos.shape[3]]\n",
    "                                                        ]\n",
    "                                                       )/3\n",
    "    ltc.get_layer(layer).set_weights([new_weight, new_bias])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de la red con el generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion customizadas para el entrenamiento del modelo \n",
    "def cambio_lr(epoch, lr):\n",
    "    if epoch == 10 or epoch == 16 :\n",
    "        for i in ['conv3d_1','conv3d_2','conv3d_3','conv3d_4', 'conv3d_5','dense_6','dense_7','dense_8']:\n",
    "            weigh_decay = ltc.get_layer(i).kernel_regularizer.get_config()['l2'] * 0.1\n",
    "            ltc.get_layer(i).kernel_regularizer = keras.regularizers.l2(weigh_decay)\n",
    "        return optimizador.learning_rate.numpy() * 0.1\n",
    "    else:\n",
    "        return optimizador.learning_rate.numpy()\n",
    "\n",
    "funciones = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(model_saves_path,'ltc_epoch_{epoch}.h5'),\n",
    "        save_best_only=True,\n",
    "        monitor='val_acc',\n",
    "        verbose=1),\n",
    "    keras.callbacks.LearningRateScheduler(cambio_lr, verbose=1),\n",
    "    keras.callbacks.CSVLogger(os.path.join(ltc_save_path,'output.csv'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 1/20\n",
      "   3568/Unknown - 3968s 1s/step - loss: 20.6857 - acc: 0.4962\n",
      "Epoch 00001: val_acc improved from -inf to 0.11316, saving model to /home/jefelitman/Saved_Models/trained_ucf/No_Encoder/no_inception/LTC-ori_split1_112x112x16_SGD_RGB_lr=0.001_DO_IC_TDM_S255_E20/model_saves/ltc_epoch_1.h5\n",
      "3568/3568 [==============================] - 5181s 1s/step - loss: 20.6857 - acc: 0.4962 - val_loss: 19.9134 - val_acc: 0.1132\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 2/20\n",
      "3567/3568 [============================>.] - ETA: 1s - loss: 10.4710 - acc: 0.7802\n",
      "Epoch 00002: val_acc improved from 0.11316 to 0.14309, saving model to /home/jefelitman/Saved_Models/trained_ucf/No_Encoder/no_inception/LTC-ori_split1_112x112x16_SGD_RGB_lr=0.001_DO_IC_TDM_S255_E20/model_saves/ltc_epoch_2.h5\n",
      "3568/3568 [==============================] - 5326s 1s/step - loss: 10.4700 - acc: 0.7803 - val_loss: 14.0306 - val_acc: 0.1431\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 3/20\n",
      "1952/3568 [===============>..............] - ETA: 56:49 - loss: 6.3518 - acc: 0.8727WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.shuffle(len(dataset.__videos_train_path__),\n",
    "                                reshuffle_each_iteration=True).batch(batch_size).prefetch(1)\n",
    "\n",
    "test_data = test_data.shuffle(len(dataset.__videos_test_path__),\n",
    "                              reshuffle_each_iteration=True).batch(batch_size).prefetch(1)\n",
    "\n",
    "historial = ltc.fit(x = train_data,\n",
    "                 epochs=epoch,\n",
    "                 callbacks=funciones,\n",
    "                 validation_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvado final definitivo del modelo una vez se detenga\n",
    "ltc.save(os.path.join(ltc_save_path,\"ltc_final_{e}.h5\".format(e=epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficas de los resultados de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(historial.history[\"loss\"],'k--')\n",
    "plt.plot(historial.history[\"val_loss\"],'b--')\n",
    "plt.title('Loss over epochs')\n",
    "plt.legend(labels=[\"Loss\",\"Val_Loss\"])\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(ltc_save_path,'train_loss_epochs_{e}.png'.format(e=epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(historial.history[\"acc\"],'k--')\n",
    "plt.plot(historial.history[\"val_acc\"],'b--')\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.legend(labels=[\"Accuracy\",\"Val_Accuracy\"])\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(ltc_save_path,'train_accuracy_epochs_{e}.png'.format(e=epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion del entrenamiento"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resultados = ltc.evaluate_generator(generator=dataset.get_test_generator(canales),\n",
    "                      steps=dataset.test_batches,\n",
    "                      max_queue_size=batch_size)\n",
    "print(\"\"\"Los resultados de la evaluacion del modelo fueron: \n",
    "Perdida: {l}\n",
    "Precision: {a}\"\"\".format(l=resultados[0],a=resultados[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
