{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuracion de grafica a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# lA ID de la GPU a usar, puede ser desde 0 hasta las N GPU's. Si es -1 significa que es en la CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../')\n",
    "from Datasets_utils.DatasetsLoader import VideoDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuraciones para Tensorflow y Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobar que estoy ejecutandome en modo eagerly\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jefelitman/DataSets/ucf101/split_1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = \"/home/jefelitman/DataSets/ucf101/split_1\"\n",
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "original_size = [89,67]\n",
    "size = [58,58]\n",
    "frames = 60\n",
    "canales = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDataGenerator(directory_path = root_path, \n",
    "                             batch_size = batch_size, \n",
    "                             original_frame_size = original_size, \n",
    "                             frame_size=size, \n",
    "                             video_frames = frames, \n",
    "                             temporal_crop = ('random', 4), \n",
    "                             frame_crop = ('random', 2), \n",
    "                             shuffle = True, \n",
    "                             conserve_original = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal LTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construccion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada de la red neuronal\n",
    "video_shape = tuple([frames]+size+[canales])\n",
    "dropout = 0.5\n",
    "entrenamiento = True\n",
    "lr = 1.#1e-3\n",
    "ltc_save_path = '/home/jefelitman/Saved_Models/LTC_58x58x60_logsoftmax_rgb_batch15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrada = keras.Input(shape=video_shape,\n",
    "                     batch_size=batch_size,\n",
    "                     name=\"Input_video\")\n",
    "#Conv1\n",
    "x = keras.layers.Conv3D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\", use_bias=False)(entrada)\n",
    "x = keras.layers.MaxPool3D(pool_size=(1,2,2),strides=(1,2,2))(x)\n",
    "\n",
    "#Conv2\n",
    "x = keras.layers.Conv3D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\", use_bias=False)(x)\n",
    "x = keras.layers.MaxPool3D(pool_size=(2,2,2),strides=(2,2,2))(x)\n",
    "\n",
    "#Conv3\n",
    "x = keras.layers.Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", use_bias=False)(x)\n",
    "x = keras.layers.MaxPool3D(pool_size=(2,2,2),strides=(2,2,2))(x)\n",
    "\n",
    "#Conv4\n",
    "x = keras.layers.Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", use_bias=False)(x)\n",
    "x = keras.layers.MaxPool3D(pool_size=(2,2,2),strides=(2,2,2))(x)\n",
    "\n",
    "#Conv5\n",
    "x = keras.layers.Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", use_bias=False)(x)\n",
    "x = keras.layers.MaxPool3D(pool_size=(2,2,2),strides=(2,2,2))(x)\n",
    "\n",
    "#fc6\n",
    "x = tf.reshape(tensor=x, shape=[batch_size,-1], name=\"Aplanado\")\n",
    "x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(dropout)(x, training=entrenamiento)\n",
    "\n",
    "#fc7\n",
    "x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(dropout)(x, training=entrenamiento)\n",
    "\n",
    "#fc8\n",
    "x = keras.layers.Dense(len(dataset.to_class), activation=\"softmax\")(x)\n",
    "salidas = tf.math.log(x)\n",
    "\n",
    "ltc = keras.Model(entrada, salidas, name=\"LTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizador del modelo\n",
    "optimizador = keras.optimizers.SGD(learning_rate=lr)\n",
    "perdida = keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(ltc, 'LTC.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltc = keras.models.load_model(os.path.join(ltc_save_path,'ltc.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LTC\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_video (InputLayer)     [(15, 60, 58, 58, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (15, 60, 58, 58, 64)      5184      \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (15, 60, 29, 29, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (15, 60, 29, 29, 128)     221184    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (15, 30, 14, 14, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (15, 30, 14, 14, 256)     884736    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (15, 15, 7, 7, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (15, 15, 7, 7, 256)       1769472   \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (15, 7, 3, 3, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (15, 7, 3, 3, 256)        1769472   \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (15, 3, 1, 1, 256)        0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Aplanado (Tensor [(15, 768)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (15, 2048)                1574912   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (15, 2048)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (15, 2048)                4196352   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (15, 2048)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (15, 101)                 206949    \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Log (TensorFlowO [(15, 101)]               0         \n",
      "=================================================================\n",
      "Total params: 10,628,261\n",
      "Trainable params: 10,628,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ltc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y, y_predicho):\n",
    "    clases = tf.argmax(y_predicho, axis=1)\n",
    "    comparaciones = tf.equal(y, clases)\n",
    "    return tf.reduce_mean(tf.cast(comparaciones, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  12745\n",
      "Train Epoch:  1  Train batch:  12745 / 12745\n",
      "Train_Loss:  4.6151204  Train_Acuraccy:  0\n",
      "Tain_max_Acuraccy: 0 at the step: 12745\n"
     ]
    }
   ],
   "source": [
    "step = 1\n",
    "train_epoch = 1\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "maximo = -1\n",
    "step_max = 0\n",
    "while train_epoch <= 1:\n",
    "    with tf.device('/CPU:0'):\n",
    "        if step % 1000 == 0:\n",
    "            ltc.save(os.path.join(ltc_save_path,'ltc.h5'))\n",
    "            print('Modelo salvado en la iteracion: {i}'.format(i=step))\n",
    "\n",
    "        if step == 80000//batch_size or step == 125000//batch_size:\n",
    "            lr = lr * 0.1\n",
    "            optimizador = keras.optimizers.SGD(learning_rate=lr)\n",
    "    \n",
    "    batch, labels = dataset.get_next_train_batch(canales)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predicciones = ltc(batch)\n",
    "        valor_perdida = perdida(labels, predicciones)\n",
    "    \n",
    "    with tf.device('/CPU:0'):\n",
    "        train_loss.append(valor_perdida.numpy())    \n",
    "        train_accuracy.append(precision(labels, predicciones).numpy())\n",
    "\n",
    "        if train_accuracy[-1] >= maximo:\n",
    "            maximo = train_accuracy[-1]\n",
    "            step_max = step\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(\"Step: \",step)\n",
    "        print(\"Train Epoch: \",train_epoch, \" Train batch: \",dataset.train_batch_index,\"/\",dataset.train_batches)\n",
    "        print(\"Train_Loss: \",train_loss[-1],\" Train_Acuraccy: \",train_accuracy[-1])\n",
    "        print(\"Tain_max_Acuraccy: {m} at the step: {s}\".format(m=maximo, s=step_max))\n",
    "        \n",
    "        if dataset.train_batch_index == dataset.train_batches:\n",
    "            train_epoch += 1\n",
    "        \n",
    "    grads = tape.gradient(valor_perdida, ltc.trainable_weights)\n",
    "    \n",
    "    optimizador.apply_gradients(zip(grads, ltc.trainable_weights))\n",
    "    \n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 64, 128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobacion de que mi modelo esta aprendiendo o variando las capas\n",
    "from copy import deepcopy\n",
    "pesos_antes = deepcopy(ltc.get_layer(index=3).get_weights()[0])\n",
    "pesos_antes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.all(pesos_antes == ltc.get_layer(index=3).get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltc.get_layer(index=3).get_weights()[0][:,:,:,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficas de los resultados de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(range(len(train_loss)), train_loss,'k--')\n",
    "plt.title('Loss over steps')\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(ltc_save_path,'train_loss.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(range(len(train_accuracy)), train_accuracy,'k--')\n",
    "plt.title('Accuracy over steps')\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(ltc_save_path,'train_accuracy.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desactivo las capas de dropout\n",
    "ltc.get_layer(index=13)._trainable = False\n",
    "ltc.get_layer(index=15)._trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "test_epoch = 1\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "entrenamiento = False\n",
    "while test_epoch == 1:\n",
    "    \n",
    "    batch, labels = dataset.get_next_test_batch(canales)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predicciones = ltc(batch)\n",
    "        valor_perdida = perdida(labels, predicciones)\n",
    "    \n",
    "    with tf.device('/CPU:0'):\n",
    "        test_loss.append(valor_perdida.numpy())    \n",
    "        test_accuracy.append(precision(labels, predicciones).numpy())\n",
    "    \n",
    "        clear_output(wait=True)\n",
    "        print(\"Step: \",step)\n",
    "        print(\"Test Epoch: \",test_epoch, \" Test batch: \",dataset.test_batch_index,\"/\",dataset.test_batches)\n",
    "        print(\"Test_Loss: \",test_loss[-1],\" Test_Acuraccy: \",test_accuracy[-1])\n",
    "        \n",
    "        if dataset.test_batch_index == dataset.test_batches:\n",
    "        test_epoch += 1\n",
    "    \n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficas de los resultados de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(range(len(test_loss)), test_loss,'k--')\n",
    "plt.title('Loss over steps')\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(ltc_save_path,'test_loss.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(range(len(test_accuracy)), test_accuracy,'k--')\n",
    "plt.title('Accuracy over steps')\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(ltc_save_path,'test_accuracy.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
