{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuracion de grafica a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# lA ID de la GPU a usar, puede ser desde 0 hasta las N GPU's. Si es -1 significa que es en la CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Datasets_utils.DatasetsLoader import VideoDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuraciones para Tensorflow y Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobar que estoy ejecutandome en modo eagerly\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/jefelitman/DataSets/ucf101/split_1\"\n",
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 30\n",
    "original_size = [171,128]\n",
    "size = [112,112]\n",
    "frames = 16\n",
    "canales = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDataGenerator(directory_path = root_path, \n",
    "                             batch_size = batch, \n",
    "                             original_frame_size = original_size, \n",
    "                             frame_size=size, \n",
    "                             video_frames = frames, \n",
    "                             temporal_crop = ('random', 4), \n",
    "                             frame_crop = ('random', 2), \n",
    "                             shuffle = True, \n",
    "                             conserve_original = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal LTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construccion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada de la red neuronal\n",
    "video_shape = tuple([frames]+size+[canales])\n",
    "dropout = 0.5\n",
    "entrenamiento = True\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrada = keras.Input(shape=video_shape,\n",
    "                     batch_size=batch,\n",
    "                     name=\"Input_video\")\n",
    "#Conv1\n",
    "x = keras.layers.Conv3D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\", use_bias=False)(entrada)\n",
    "x = keras.layers.MaxPool3D(pool_size=(1,2,2),strides=(1,2,2))(x)\n",
    "\n",
    "#Conv2\n",
    "x = keras.layers.Conv3D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\", use_bias=False)(x)\n",
    "x = keras.layers.MaxPool3D(pool_size=(2,2,2),strides=(2,2,2))(x)\n",
    "\n",
    "#Conv3\n",
    "x = keras.layers.Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", use_bias=False)(x)\n",
    "x = keras.layers.MaxPool3D(pool_size=(2,2,2),strides=(2,2,2))(x)\n",
    "\n",
    "#Conv4\n",
    "x = keras.layers.Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", use_bias=False)(x)\n",
    "x = keras.layers.MaxPool3D(pool_size=(2,2,2),strides=(2,2,2))(x)\n",
    "\n",
    "#Conv5\n",
    "x = keras.layers.Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", use_bias=False)(x)\n",
    "x = keras.layers.MaxPool3D(pool_size=(2,2,2),strides=(1,1,1))(x)\n",
    "\n",
    "#fc6\n",
    "x = tf.reshape(tensor=x, shape=[batch,-1], name=\"Aplanado\")\n",
    "x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(dropout)(x, training=entrenamiento)\n",
    "\n",
    "#fc7\n",
    "x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(dropout)(x, training=entrenamiento)\n",
    "\n",
    "#fc8\n",
    "salidas= keras.layers.Dense(len(dataset.to_class), activation=\"softmax\")(x)\n",
    "\n",
    "ltc = keras.Model(entrada, salidas, name=\"LTC\")\n",
    "ltc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizador del modelo\n",
    "optimizador = keras.optimizers.SGD(learning_rate=lr)\n",
    "perdida = keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(ltc, 'LTC.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltc = keras.models.load_model('/home/jefelitman/Saved_Models/LTC_112x112x16_rgb_batch30/ltc.h5'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y, y_predicho):\n",
    "    clases = tf.argmax(y_predicho, axis=1)\n",
    "    comparaciones = tf.equal(y, clases)\n",
    "    return tf.reduce_mean(tf.cast(comparaciones, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "train_epoch = 1\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "maximo = -1\n",
    "step_max = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if step % 1000 == 0:\n",
    "        ltc.save('/home/jefelitman/Saved_Models/LTC_112x112x16_rgb_batch30/ltc.h5')\n",
    "        print('Modelo salvado en la iteracion: {i}'.format(i=step))\n",
    "        \n",
    "    if step == 80000 or step == 125000:\n",
    "        lr = lr * 0.1\n",
    "        optimizador = keras.optimizers.SGD(learning_rate=lr)\n",
    "    \n",
    "    if dataset.train_batch_index == dataset.train_batches:\n",
    "        train_epoch += 1\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    print(\"Step: \",step)\n",
    "    print(\"Train Epoch: \",train_epoch, \" Train batch: \",dataset.train_batch_index+1,\"/\",dataset.train_batches)\n",
    "    \n",
    "    batch, labels = dataset.get_next_train_batch(canales)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predicciones = ltc(batch)\n",
    "        valor_perdida = perdida(labels, predicciones)\n",
    "    \n",
    "    train_loss.append(valor_perdida)    \n",
    "    train_accuracy.append(precision(labels, predicciones))\n",
    "    \n",
    "    if train_accuracy[-1] > maximo:\n",
    "        maximo = train_accuracy[-1]\n",
    "        step_max = step\n",
    "        \n",
    "    print(\"Train_Loss: \",train_loss[-1].numpy(),\" Train_Acuraccy: \",train_accuracy[-1].numpy())\n",
    "    print(\"Tain_max_Acuraccy: {m} at the step: {s}\".format(m=maximo, s=step_max))\n",
    "        \n",
    "    grads = tape.gradient(valor_perdida, ltc.trainable_weights)\n",
    "    \n",
    "    optimizador.apply_gradients(zip(grads, ltc.trainable_weights))\n",
    "    \n",
    "    step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
