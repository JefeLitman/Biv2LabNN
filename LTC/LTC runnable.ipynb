{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# lA ID de la GPU a usar, puede ser desde 0 hasta las N GPU's. Si es -1 significa que es en la CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pathlib\n",
    "import random\n",
    "import IPython.display as display\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuraciones de TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuracion de TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuracion de TensorFlow 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log device placement corresponde a si yo quiero ver la informacion en donde se mapea o guardan las variables que creo\n",
    "config = tf.ConfigProto(log_device_placement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo eagerly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobar que estoy ejecutandome en modo eagerly\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploracion Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../DataSets/UCF101')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = pathlib.Path(\"../DataSets/ucf101\")\n",
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13320"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_rgb_path = list(root_path.glob('frames/*'))\n",
    "videos_rgb_path = [str(video) for video in videos_rgb_path]\n",
    "len(videos_rgb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../DataSets/UCF101/frames/v_PlayingPiano_g24_c04',\n",
       " '../DataSets/UCF101/frames/v_RopeClimbing_g20_c02',\n",
       " '../DataSets/UCF101/frames/v_BlowingCandles_g18_c01',\n",
       " '../DataSets/UCF101/frames/v_Rowing_g05_c04',\n",
       " '../DataSets/UCF101/frames/v_Archery_g23_c07',\n",
       " '../DataSets/UCF101/frames/v_HeadMassage_g16_c04',\n",
       " '../DataSets/UCF101/frames/v_JumpingJack_g07_c04',\n",
       " '../DataSets/UCF101/frames/v_Shotput_g08_c07',\n",
       " '../DataSets/UCF101/frames/v_Skiing_g16_c04',\n",
       " '../DataSets/UCF101/frames/v_PlayingCello_g09_c05']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_rgb_path[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../DataSets/UCF101/frames/v_HandstandPushups_g16_c07\n"
     ]
    }
   ],
   "source": [
    "video_path = pathlib.Path(random.choice(videos_rgb_path))\n",
    "frames_path = list(video_path.glob('*'))\n",
    "frames_path = [str(frame_path) for frame_path in frames_path]\n",
    "print(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.display(display.Image(random.choice(frames_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ApplyEyeMakeup',\n",
       " 'ApplyLipstick',\n",
       " 'Archery',\n",
       " 'BabyCrawling',\n",
       " 'BalanceBeam',\n",
       " 'BandMarching',\n",
       " 'BaseballPitch',\n",
       " 'BasketballDunk',\n",
       " 'Basketball',\n",
       " 'BenchPress']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres_clases = sorted(pathlib.Path(item).name for item in videos_rgb_path if pathlib.Path(item).is_dir())\n",
    "nombres_clases = [clase.split(\"_\")[1] for clase in nombres_clases]\n",
    "\n",
    "#Extraccion de todos los tipos de clases en un vector de python\n",
    "clases = []\n",
    "for clase in nombres_clases:\n",
    "    if clase not in clases:\n",
    "        clases.append(clase)\n",
    "\n",
    "#label_names, __ = tf.unique(label_names)\n",
    "nombres_clases = clases\n",
    "nombres_clases[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clase_a_numero = dict((name, index) for index,name in enumerate(nombres_clases))\n",
    "len(clase_a_numero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63, 74, 13, 75, 2, 38, 47, 78, 80, 58]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clases_videos = [clase_a_numero[pathlib.Path(item).name.split(\"_\")[1]] for item in videos_rgb_path]\n",
    "clases_videos[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizacion del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../DataSets\n",
    "\n",
    "os.mkdir(\"ucf101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"ucf101/frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_rgb_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como cargar los videos usando la libreria de tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forma de cargar los videos para usarlos como dataset pero ocupa mucha memoria, entonces se va hacer buffering con tensor\n",
    "videos = []\n",
    "for video_path in videos_rgb_path:\n",
    "    video = []\n",
    "    for frame_path in sorted(list(video_path.glob('*'))):\n",
    "        frame_raw = tf.io.read_file(str(frame_path))\n",
    "        frame_tensor = tf.image.decode_image(frame_raw, channels=3)\n",
    "        frame_tensor = tf.image.resize(frame_tensor,[128,171])\n",
    "        frame_tensor = seleccionar_cuadro_aleatorio(frame_tensor, 112)\n",
    "        video.append(frame_tensor)\n",
    "    video = tf.convert_to_tensor(video)\n",
    "    video = seleccionar_extension_temporal(video, 16)\n",
    "    videos.append(video)\n",
    "videos = tf.convert_to_tensor(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionar_cuadro_aleatorio(imagen, nueva_dimension):\n",
    "    pos_y = randint(0,imagen.shape[0].value - nueva_dimension)\n",
    "    pos_x = randint(0,imagen.shape[1].value - nueva_dimension)\n",
    "    return imagen[pos_y : pos_y + nueva_dimension , pos_x : pos_x + nueva_dimension, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionar_extension_temporal(video, nro_frames):\n",
    "    extension = randint(0,video.shape[0].value - nro_frames)\n",
    "    return video[extension : extension + nro_frames, : , :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion sin ser usada aun\n",
    "def procesar_frame(frame_path):\n",
    "    frame_raw = tf.io.read_file(str(frame_path))\n",
    "    frame_tensor = tf.image.decode_image(frame_raw, channels=3)\n",
    "    frame_tensor = tf.image.resize(frame_tensor,[128,171])\n",
    "    return frame_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_preprocesar_video(video_path):\n",
    "    video = []\n",
    "    for frame_path in sorted(list(pathlib.Path(video_path.numpy()).glob('*'))):\n",
    "        frame_raw = tf.io.read_file(str(frame_path))\n",
    "        frame_tensor = tf.image.decode_image(frame_raw, channels=3)\n",
    "        frame_tensor = tf.image.resize(frame_tensor,[128,171])\n",
    "        frame_tensor = seleccionar_cuadro_aleatorio(frame_tensor, 112)\n",
    "        video.append(frame_tensor)\n",
    "    video = tf.convert_to_tensor(video)\n",
    "    video = seleccionar_extension_temporal(video, 16)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creacion de los datasets de TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Construccion del dataset a partir de los path y cargar los datos usando prefetch\n",
    "videos_rgb_path_ds = tf.data.Dataset.from_tensor_slices(videos_rgb_path)\n",
    "videos_rgb_path_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in converted code:\n\n    <ipython-input-17-f22c65689ba7>:3 cargar_preprocesar_video  *\n        for frame_path in sorted(list(pathlib.Path(video_path.numpy()).glob('*'))):\n\n    AttributeError: 'Tensor' object has no attribute 'numpy'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ffe0223ecf83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvideos_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideos_rgb_path_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcargar_preprocesar_video\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m       return ParallelMapDataset(\n\u001b[0;32m-> 1214\u001b[0;31m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3453\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3454\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3455\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3456\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   2693\u001b[0m       \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1852\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 1854\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2687\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   2688\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2689\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2634\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2635\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in converted code:\n\n    <ipython-input-17-f22c65689ba7>:3 cargar_preprocesar_video  *\n        for frame_path in sorted(list(pathlib.Path(video_path.numpy()).glob('*'))):\n\n    AttributeError: 'Tensor' object has no attribute 'numpy'\n"
     ]
    }
   ],
   "source": [
    "videos_ds = videos_rgb_path_ds.map(cargar_preprocesar_video, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir los tensores a texto con tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories_ds = tf.data.Dataset.list_files(videos_rgb_path[0]+\"/*\")\n",
    "\n",
    "for video in directories_ds:\n",
    "    print(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_rgb_path_ds = tf.data.TextLineDataset(videos_rgb_path_ds)\n",
    "videos_rgb_path_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in videos_rgb_path_ds:\n",
    "    frames = tf.data.TextLineDataset(video)\n",
    "    #print(frames)\n",
    "    #print(frames.list_files(\"*\"))\n",
    "    for frame in frames.list_files(\"*\"):\n",
    "        print(frame)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.get_output_stype(videos_rgb_path_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_rgb_path_ds.list_files(\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listar directorios usando la libreria tf.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elemento in videos_rgb_path_ds:\n",
    "    print(elemento)\n",
    "    #print(tf.io.gfile.listdir(elemento))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stackoverflow.com/questions/44416764/loading-folders-of-images-in-tensorflow\n",
    "https://github.com/hx173149/C3D-tensorflow\n",
    "https://gist.github.com/tomrunia/7ef5d40639f2ae41fb71d3352a701e4a\n",
    "https://github.com/ferreirafabio/video2tfrecord\n",
    "https://stackoverflow.com/questions/42978731/video-frames-as-inputs-to-the-tensorflow-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.io.gfile.listdir(tf.constant(\"../DataSets/UCF101/frames/v_PlayingPiano_g24_c04\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_ds = videos_rgb_path_ds.map(cargar_preprocesar_video, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas_ds = tf.data.Dataset.from_tensor_slices(clases_videos)\n",
    "etiquetas_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LTC import LTC\n",
    "\n",
    "\n",
    "\n",
    "model = LTC(\n",
    "    entrada = None,\n",
    "    etiquetas = None,\n",
    "    num_clases = None,\n",
    "    batch_size = 30,\n",
    "    dropout = 0.5,\n",
    "    entramiento = True):\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors={'step': model.global_step,\n",
    "               'loss': model.cost,\n",
    "               'precision': precision},\n",
    "      every_n_iter=100)\n",
    "\n",
    "training_session = tf.train.MonitoredTrainingSession(\n",
    "    checkpoint_dir=\"./Checkpoints\",\n",
    "      hooks=[logging_hook, _LearningRateSetterHook()],\n",
    "      chief_only_hooks=[summary_hook],\n",
    "      # Since we provide a SummarySaverHook, we need to disable default\n",
    "      # SummarySaverHook. To do that we set save_summaries_steps to 0.\n",
    "      save_summaries_steps=0,\n",
    "      config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.math.purdue.edu/~nwinovic/slides/Getting_Started_with_TensorFlow_II.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
