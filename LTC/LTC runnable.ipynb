{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# lA ID de la GPU a usar, puede ser desde 0 hasta las N GPU's. Si es -1 significa que es en la CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import IPython.display as display\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuraciones de TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuracion de TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuracion de TensorFlow 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo eagerly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobar que estoy ejecutandome en modo eagerly\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jefelitman/DataSets/ucf101/split_1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = \"/home/jefelitman/DataSets/ucf101/split_1\"\n",
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = sorted(os.listdir(root_path))\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = [\"train\",\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from Datasets_utils.DatasetsLoader import UCF101\n",
    "\n",
    "dataset = UCF101(root_path,10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, labels = dataset.get_next_train_batch([112,112],16)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LTC_v2 import LTC\n",
    "\n",
    "Sesion = tf.Session(config=config)\n",
    "\n",
    "ltc = LTC(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1012 03:54:29.137646 139961901201216 deprecation_wrapper.py:119] From /home/jefelitman/Biv2LabNN/LTC/LTC_v2.py:117: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W1012 03:54:29.138848 139961901201216 deprecation_wrapper.py:119] From /home/jefelitman/Biv2LabNN/LTC/LTC_v2.py:118: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W1012 03:54:29.139806 139961901201216 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1012 03:54:29.185844 139961901201216 deprecation_wrapper.py:119] From /home/jefelitman/Biv2LabNN/LTC/LTC_v2.py:162: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
      "\n",
      "W1012 03:54:29.223805 139961901201216 deprecation_wrapper.py:119] From /home/jefelitman/Biv2LabNN/LTC/LTC_v2.py:73: The name tf.losses.log_loss is deprecated. Please use tf.compat.v1.losses.log_loss instead.\n",
      "\n",
      "W1012 03:54:29.242184 139961901201216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1012 03:54:29.258035 139961901201216 deprecation_wrapper.py:119] From /home/jefelitman/Biv2LabNN/LTC/LTC_v2.py:81: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W1012 03:54:29.261703 139961901201216 deprecation_wrapper.py:119] From /home/jefelitman/Biv2LabNN/LTC/LTC_v2.py:100: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'conv1/W:0' shape=(3, 3, 3, 3, 64) dtype=float32_ref>\", \"<tf.Variable 'conv2/W:0' shape=(3, 3, 3, 64, 128) dtype=float32_ref>\", \"<tf.Variable 'conv3/W:0' shape=(3, 3, 3, 128, 256) dtype=float32_ref>\", \"<tf.Variable 'conv4/W:0' shape=(3, 3, 3, 256, 256) dtype=float32_ref>\", \"<tf.Variable 'conv5/W:0' shape=(3, 3, 3, 256, 256) dtype=float32_ref>\", \"<tf.Variable 'fc6/W:0' shape=(4096, 2048) dtype=float32_ref>\", \"<tf.Variable 'fc6/B:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'fc7/W:0' shape=(2048, 2048) dtype=float32_ref>\", \"<tf.Variable 'fc7/B:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'fc8/W:0' shape=(2048, 101) dtype=float32_ref>\", \"<tf.Variable 'fc8/B:0' shape=(101,) dtype=float32_ref>\"] and loss Tensor(\"costo/Mean:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7b4274a0389f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Batch: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m112\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mSesion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mltc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentrenar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Biv2LabNN/LTC/LTC_v2.py\u001b[0m in \u001b[0;36mentrenar\u001b[0;34m(self, entrada, etiquetas, dropout, learning_rate)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0moptimizador\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moptimizador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperdida\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"un_paso_aprendizaje\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformateo_stride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    408\u001b[0m           \u001b[0;34m\"No gradients provided for any variable, check your graph for ops\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m           \u001b[0;34m\" that do not support gradients, between variables %s and loss %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'conv1/W:0' shape=(3, 3, 3, 3, 64) dtype=float32_ref>\", \"<tf.Variable 'conv2/W:0' shape=(3, 3, 3, 64, 128) dtype=float32_ref>\", \"<tf.Variable 'conv3/W:0' shape=(3, 3, 3, 128, 256) dtype=float32_ref>\", \"<tf.Variable 'conv4/W:0' shape=(3, 3, 3, 256, 256) dtype=float32_ref>\", \"<tf.Variable 'conv5/W:0' shape=(3, 3, 3, 256, 256) dtype=float32_ref>\", \"<tf.Variable 'fc6/W:0' shape=(4096, 2048) dtype=float32_ref>\", \"<tf.Variable 'fc6/B:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'fc7/W:0' shape=(2048, 2048) dtype=float32_ref>\", \"<tf.Variable 'fc7/B:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'fc8/W:0' shape=(2048, 101) dtype=float32_ref>\", \"<tf.Variable 'fc8/B:0' shape=(101,) dtype=float32_ref>\"] and loss Tensor(\"costo/Mean:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": [
    "for i in range(dataset.train_batches):\n",
    "    print(\"Batch: \",i)\n",
    "    batch, labels = dataset.get_next_train_batch([112,112],16)\n",
    "    Sesion.run(ltc.entrenar(batch,labels,0.5,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'costo/Mean_1:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltc.precisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LTC_v2 import LTC\n",
    "\n",
    "model = LTC(101):\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors={'step': model.global_step,\n",
    "               'loss': model.cost,\n",
    "               'precision': precision},\n",
    "      every_n_iter=100)\n",
    "\n",
    "training_session = tf.train.MonitoredTrainingSession(\n",
    "    checkpoint_dir=\"./Checkpoints\",\n",
    "      hooks=[logging_hook, _LearningRateSetterHook()],\n",
    "      chief_only_hooks=[summary_hook],\n",
    "      # Since we provide a SummarySaverHook, we need to disable default\n",
    "      # SummarySaverHook. To do that we set save_summaries_steps to 0.\n",
    "      save_summaries_steps=0,\n",
    "      config=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.math.purdue.edu/~nwinovic/slides/Getting_Started_with_TensorFlow_II.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
