{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las bibliotecas\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# lA ID de la GPU a usar, puede ser desde 0 hasta las N GPU's. Si es -1 significa que es en la CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\";\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "!wget -q https://raw.githubusercontent.com/JefeLitman/VideoDataGenerator/master/DatasetsLoader.py -O DatasetsLoader.py\n",
    "from DatasetsLoader import VideoDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion del tf_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):  #Lo utilizamos para los datos ya como tal (imagenes o volumenes)\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def video_example(video, label):\n",
    "    feature = {\n",
    "        'frames': _int64_feature(video.shape[0]),\n",
    "        'height': _int64_feature(video.shape[1]),\n",
    "        'width': _int64_feature(video.shape[2]),\n",
    "        'depth': _int64_feature(video.shape[3]),\n",
    "        'label': _int64_feature(label),\n",
    "        'video_raw': _bytes_feature(video.tostring()),\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/jefelitman/DataSets/hmdb51/split_1\"\n",
    "\n",
    "batch_size = 1\n",
    "original_size = [89,67]\n",
    "size = [58,58]\n",
    "frames = 60\n",
    "canales = 3\n",
    "\n",
    "def custom_steps_temporal(frames):\n",
    "    paso = len(frames)//60\n",
    "    videos = []\n",
    "    for i in range(paso):\n",
    "        indices = range(i, len(frames),paso)\n",
    "        videos.append([frames[j] for j in indices[:60]])\n",
    "    return videos\n",
    "def flip_vertical(volume):\n",
    "    return np.flip(volume, (0, 2))[::-1]\n",
    "def video_transf(video):\n",
    "    escalador = MinMaxScaler()\n",
    "    new_video = video.reshape((video.shape[0]*video.shape[1]*video.shape[2]*video.shape[3],1))\n",
    "    new_video = escalador.fit_transform(new_video)\n",
    "    return new_video.reshape((video.shape[0],video.shape[1],video.shape[2],video.shape[3]))\n",
    "\n",
    "dataset = VideoDataGenerator(directory_path = root_path, \n",
    "                             table_paths = None, \n",
    "                             batch_size = batch_size, \n",
    "                             original_frame_size = original_size, \n",
    "                             frame_size=size, \n",
    "                             video_frames = frames, \n",
    "                             temporal_crop = (\"custom\", custom_steps_temporal),\n",
    "                             video_transformation = [(\"augmented\",flip_vertical),(\"full\", video_transf)],\n",
    "                             frame_crop = (None, None), \n",
    "                             shuffle = False,\n",
    "                             shuffle_after_epoch = False,\n",
    "                             conserve_original = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/home/jefelitman/DataSets/hmdb51'\n",
    "\n",
    "record = os.path.join(save_path,'hmdb_split_1_train.tfrecord')\n",
    "with tf.io.TFRecordWriter(record) as writer:\n",
    "    for b in range(dataset.train_batches):\n",
    "        video , label = dataset.get_next_train_batch(1)\n",
    "        tf_example = video_example(video[0], label[0])\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "        \n",
    "record = os.path.join(save_path,'hmdb_split_1_test.tfrecord')\n",
    "with tf.io.TFRecordWriter(record) as writer:\n",
    "    for b in range(dataset.test_batches):\n",
    "        video , label = dataset.get_next_test_batch(1)\n",
    "        tf_example = video_example(video[0], label[0])\n",
    "        writer.write(tf_example.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
